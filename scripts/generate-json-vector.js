const fs = require("fs");
const path = require("path");

async function generate() {
  console.log("üì• ƒêang t·∫£i Model AI...");
  const { pipeline } = await import("@xenova/transformers");
  const extractor = await pipeline(
    "feature-extraction",
    "Xenova/all-MiniLM-L6-v2"
  );

  // 1. ƒê·ªçc d·ªØ li·ªáu g·ªëc
  const dataPath = path.join(__dirname, "../public/data/anime_full.json");
  const rawData = fs.readFileSync(dataPath, "utf-8");
  const animes = JSON.parse(rawData);

  console.log(`üöÄ B·∫Øt ƒë·∫ßu t·∫°o vector cho ${animes.length} b·ªô anime...`);

  const embeddingsData = []; // M·∫£ng ch·ª©a k·∫øt qu·∫£

  for (let i = 0; i < animes.length; i++) {
    const anime = animes[i];

    // Chu·∫©n b·ªã text
    const textToEmbed = `
      Title: ${anime.title}
      Genres: ${anime.genres?.map((g) => g.name).join(", ") || ""}
      Studio: ${anime.studios?.map((s) => s.name).join(", ") || ""}
      Synopsis: ${anime.synopsis || ""}
    `;

    // T·∫°o vector
    const output = await extractor(textToEmbed, {
      pooling: "mean",
      normalize: true, // Quan tr·ªçng: ƒê√£ chu·∫©n h√≥a th√¨ t√≠nh kho·∫£ng c√°ch c·ª±c nhanh
    });

    // L∆∞u g·ªçn nh·∫π: Ch·ªâ c·∫ßn ID v√† Vector
    embeddingsData.push({
      id: anime.id,
      vector: Array.from(output.data),
    });

    if (i % 50 === 0) process.stdout.write(`.`);
  }

  // 2. Ghi ra file ri√™ng
  const outputPath = path.join(__dirname, "../public/data/aembeddings.json");
  fs.writeFileSync(outputPath, JSON.stringify(embeddingsData));

  console.log(`\n‚úÖ Xong! File vector l∆∞u t·∫°i: ${outputPath}`);
  console.log(
    `dung l∆∞·ª£ng file kho·∫£ng: ${(
      fs.statSync(outputPath).size /
      1024 /
      1024
    ).toFixed(2)} MB`
  );
}

generate();
